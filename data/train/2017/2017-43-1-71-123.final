Highly	O
frequent	O
in	O
language	B
and	O
communication	B
,	O
metaphor	B
represents	O
a	O
significant	O
challenge	O
for	O
Natural	B
Language	I
Processing	I
(	O
NLP	B
)	O
applications	I
.	O
	O
Computational	B
work	I
on	I
metaphor	I
has	O
traditionally	O
evolved	O
around	O
the	O
use	O
of	O
hand	O
-	O
coded	O
knowledge	O
,	O
making	O
the	O
systems	O
hard	O
to	O
scale	O
.	O
	O
Recent	O
years	O
have	O
witnessed	O
a	O
rise	O
in	O
statistical	B
approaches	I
to	O
metaphor	B
processing	I
.	O
	O
However	O
,	O
these	O
approaches	O
often	O
require	O
extensive	B
human	I
annotation	I
effort	O
and	O
are	O
predominantly	O
evaluated	O
within	O
a	O
limited	O
domain	O
.	O
	O
In	O
contrast	O
,	O
we	O
experiment	O
with	O
weakly	O
supervised	B
and	O
unsupervised	B
techniques	I
—	O
with	O
little	O
or	O
no	O
annotation	B
—	O
to	O
generalize	O
higher	O
-	O
level	O
mechanisms	O
of	O
metaphor	B
from	O
distributional	B
properties	I
of	I
concepts	I
.	O
	O
We	O
investigate	O
different	O
levels	O
and	O
types	O
of	O
supervision	B
(	O
learning	B
from	O
linguistic	B
examples	O
vs.	O
learning	B
from	O
a	O
given	O
set	O
of	O
metaphorical	B
mappings	I
vs.	O
learning	B
without	I
annotation	I
)	O
in	O
flat	O
and	O
hierarchical	O
,	O
unconstrained	O
and	O
constrained	O
clustering	B
settings	I
.	O
	O
Our	O
aim	O
is	O
to	O
identify	O
the	O
optimal	O
type	B
of	I
supervision	I
for	O
a	O
learning	B
algorithm	I
that	O
discovers	B
patterns	I
of	O
metaphorical	B
association	I
from	B
text	I
.	O
	O
In	O
order	O
to	O
investigate	O
the	O
scalability	B
and	O
adaptability	B
of	O
our	O
models	B
,	O
we	O
applied	O
them	O
to	O
data	B
in	I
three	I
languages	I
from	O
different	B
language	I
groups	I
—	O
English	B
,	O
Spanish	B
,	O
and	O
Russian	B
—	O
achieving	O
state	B
-	I
of	I
-	I
the	I
-	II
art	I
results	O
with	O
little	B
supervision	I
.	O
	O
Finally	O
,	O
we	O
demonstrate	O
that	O
statistical	B
methods	I
an	O
facilitate	O
and	O
scale	B
up	I
cross	B
-	I
linguistic	I
research	O
on	O
metaphor	B
.	O
