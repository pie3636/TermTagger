Named	B
entity	I
recognition	I
systems	O
achieve	O
remarkable	O
performance	O
on	O
domains	O
such	O
as	O
English	O
news	O
.	O
It	O
is	O
natural	O
to	O
ask	O
:	O
What	O
are	O
these	O
models	O
actually	O
learning	O
to	O
achieve	O
this	O
?	O
Are	O
they	O
merely	O
memorizing	O
the	O
names	O
themselves	O
?	O
Or	O
are	O
they	O
capable	O
of	O
interpreting	O
the	O
text	O
and	O
inferring	O
the	O
correct	O
entity	B
type	I
from	O
the	O
linguistic	B
context	I
?	O
We	O
examine	O
these	O
questions	O
by	O
contrasting	O
the	O
performance	O
of	O
several	O
variants	O
of	O
architectures	O
for	O
named	B
entity	I
recognition	I
,	O
with	O
some	O
provided	O
only	O
representations	O
of	O
the	O
context	O
as	O
features	O
.	O
We	O
experiment	O
with	O
GloVe	B
-	I
based	I
BiLSTM	B
-	I
CRF	I
as	O
well	O
as	O
BERT	B
.	O
We	O
find	O
that	O
context	O
does	O
influence	O
predictions	O
,	O
but	O
the	O
main	O
factor	O
driving	O
high	O
performance	O
is	O
learning	O
the	O
named	B
tokens	I
themselves	O
.	O
Furthermore	O
,	O
we	O
find	O
that	O
BERT	B
is	O
not	O
always	O
better	O
at	O
recognizing	O
predictive	B
contexts	I
compared	O
to	O
a	O
BiLSTM	B
-	I
CRF	I
model	I
.	O
We	O
enlist	O
human	O
annotators	B
to	O
evaluate	O
the	O
feasibility	O
of	O
inferring	O
entity	B
types	I
from	O
context	O
alone	O
and	O
find	O
that	O
humans	O
are	O
also	O
mostly	O
unable	O
to	O
infer	O
entity	B
types	I
for	O
the	O
majority	O
of	O
examples	O
on	O
which	O
the	O
context	B
-	I
only	I
system	I
made	O
errors	O
.	O
However	O
,	O
there	O
is	O
room	O
for	O
improvement	O
:	O
A	O
system	O
should	O
be	O
able	O
to	O
recognize	O
any	O
named	B
entity	I
in	O
a	O
predictive	B
context	I
correctly	O
and	O
our	O
experiments	O
indicate	O
that	O
current	O
systems	O
may	O
be	O
improved	O
by	O
such	O
capability	O
.	O
Our	O
human	O
study	O
also	O
revealed	O
that	O
systems	O
and	O
humans	O
do	O
not	O
always	O
learn	O
the	O
same	O
contextual	O
clues	O
,	O
and	O
context	B
-	I
only	I
systems	I
are	O
sometimes	O
correct	O
even	O
when	O
humans	O
fail	O
to	O
recognize	O
the	O
entity	B
type	I
from	O
the	O
context	O
.	O
Finally	O
,	O
we	O
find	O
that	O
one	O
issue	O
contributing	O
to	O
model	B
errors	I
is	O
the	O
use	O
of	O
“	B
entangled	I
”	I
representations	I
that	O
encode	B
both	O
contextual	O
and	O
local	B
token	I
information	I
into	O
a	O
single	O
vector	B
,	O
which	O
can	O
obscure	O
clues	O
.	O
Our	O
results	O
suggest	O
that	O
designing	O
models	O
that	O
explicitly	O
operate	O
over	O
representations	B
of	I
local	I
inputs	I
and	O
context	O
,	O
respectively	O
,	O
may	O
in	O
some	O
cases	O
improve	O
performance	O
.	O
In	O
light	O
of	O
these	O
and	O
related	O
findings	O
,	O
we	O
highlight	O
directions	O
for	O
future	O
work	O
.	O