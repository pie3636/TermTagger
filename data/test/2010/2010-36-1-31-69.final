Many	O
NLP	B
applications	I
entail	O
that	O
texts	O
are	O
classified	O
based	O
on	O
their	O
semantic	B
distance	I
(	O
how	O
similar	O
or	O
different	O
the	O
texts	O
are	O
)	O
.	O
For	O
example	O
,	O
comparing	O
the	O
text	O
of	O
a	O
new	O
document	O
to	O
that	O
of	O
documents	O
of	O
known	O
topics	O
can	O
help	O
identify	O
the	O
topic	O
of	O
the	O
new	O
text	O
.	O
Typically	O
,	O
a	O
distributional	B
distance	I
is	O
used	O
to	O
capture	O
the	O
implicit	B
semantic	I
distance	I
between	O
two	O
pieces	O
of	O
text	O
.	O
However	O
,	O
such	O
approaches	O
do	O
not	O
take	O
into	O
account	O
the	O
semantic	B
relations	I
between	O
words	O
.	O
In	O
this	O
article	O
,	O
we	O
introduce	O
an	O
alternative	O
method	O
of	O
measuring	O
the	O
semantic	B
distance	I
between	O
texts	O
that	O
integrates	O
distributional	B
information	I
and	O
ontological	B
knowledge	I
within	O
a	O
network	B
flow	I
formalism	I
.	O
We	O
first	O
represent	O
each	O
text	O
as	O
a	O
collection	O
of	O
frequency	B
-	I
weighted	I
concepts	I
within	O
an	O
ontology	B
.	O
We	O
then	O
make	O
use	O
of	O
a	O
network	B
flow	I
method	I
which	O
provides	O
an	O
efficient	O
way	O
of	O
explicitly	O
measuring	O
the	O
frequency	B
-	I
weighted	I
ontological	I
distance	I
between	O
the	O
concepts	O
across	O
two	O
texts	O
.	O
We	O
evaluate	O
our	O
method	O
in	O
a	O
variety	O
of	O
NLP	B
tasks	I
,	O
and	O
find	O
that	O
it	O
performs	O
well	O
on	O
two	O
of	O
three	O
tasks	O
.	O
We	O
develop	O
a	O
new	O
measure	O
of	O
semantic	B
coherence	I
that	O
enables	O
us	O
to	O
account	O
for	O
the	O
performance	O
difference	O
across	O
the	O
three	O
data	B
sets	I
,	O
shedding	O
light	O
on	O
the	O
properties	O
of	O
a	O
data	B
set	I
that	O
lends	O
itself	O
well	O
to	O
our	O
method	O
.	O
